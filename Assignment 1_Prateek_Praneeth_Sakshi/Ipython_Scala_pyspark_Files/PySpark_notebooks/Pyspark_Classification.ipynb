{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Loading libraries and setting spark context\n",
    "from pyspark.mllib.classification import SVMWithSGD, SVMModel\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS \n",
    "from pyspark.mllib.classification import LogisticRegressionWithSGD\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn import metrics\n",
    "from numpy import array\n",
    "import numpy as np\n",
    "#sc = SparkContext(appName=\"Classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Importing the winedata to a RDD\n",
    "dataFile = sc.textFile(\"C:\\Users\\Bellamkonda\\Desktop\\Spark\\wine1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'0,7 0.27 0.36 20.7 0.045 45 170 1.001 3 0.45 8.8',\n",
       " u'0,6.3 0.3 0.34 1.6 0.049 14 132 0.994 3.3 0.49 9.5',\n",
       " u'0,8.1 0.28 0.4 6.9 0.05 30 97 0.9951 3.26 0.44 10.1',\n",
       " u'0,7.2 0.23 0.32 8.5 0.058 47 186 0.9956 3.19 0.4 9.9',\n",
       " u'0,7.2 0.23 0.32 8.5 0.058 47 186 0.9956 3.19 0.4 9.9',\n",
       " u'0,8.1 0.28 0.4 6.9 0.05 30 97 0.9951 3.26 0.44 10.1',\n",
       " u'0,6.2 0.32 0.16 7 0.045 30 136 0.9949 3.18 0.47 9.6',\n",
       " u'0,7 0.27 0.36 20.7 0.045 45 170 1.001 3 0.45 8.8',\n",
       " u'0,6.3 0.3 0.34 1.6 0.049 14 132 0.994 3.3 0.49 9.5',\n",
       " u'0,8.1 0.22 0.43 1.5 0.044 28 129 0.9938 3.22 0.45 11']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Viewing the first 10 records in the datafile RDD\n",
    "dataFile.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Parsing function and creating a labeled point for dependent and independent variables\n",
    "def line_to_array(line):\n",
    "    string_array = line.split(',')\n",
    "    return LabeledPoint(string_array[0], string_array[1].split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Using map function to parse the data\n",
    "parsedData = dataFile.map(line_to_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(0.0, [7.0,0.27,0.36,20.7,0.045,45.0,170.0,1.001,3.0,0.45,8.8]),\n",
       " LabeledPoint(0.0, [6.3,0.3,0.34,1.6,0.049,14.0,132.0,0.994,3.3,0.49,9.5]),\n",
       " LabeledPoint(0.0, [8.1,0.28,0.4,6.9,0.05,30.0,97.0,0.9951,3.26,0.44,10.1]),\n",
       " LabeledPoint(0.0, [7.2,0.23,0.32,8.5,0.058,47.0,186.0,0.9956,3.19,0.4,9.9]),\n",
       " LabeledPoint(0.0, [7.2,0.23,0.32,8.5,0.058,47.0,186.0,0.9956,3.19,0.4,9.9]),\n",
       " LabeledPoint(0.0, [8.1,0.28,0.4,6.9,0.05,30.0,97.0,0.9951,3.26,0.44,10.1]),\n",
       " LabeledPoint(0.0, [6.2,0.32,0.16,7.0,0.045,30.0,136.0,0.9949,3.18,0.47,9.6]),\n",
       " LabeledPoint(0.0, [7.0,0.27,0.36,20.7,0.045,45.0,170.0,1.001,3.0,0.45,8.8]),\n",
       " LabeledPoint(0.0, [6.3,0.3,0.34,1.6,0.049,14.0,132.0,0.994,3.3,0.49,9.5]),\n",
       " LabeledPoint(0.0, [8.1,0.22,0.43,1.5,0.044,28.0,129.0,0.9938,3.22,0.45,11.0])]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Observing the first 10 records in the parsedData RDD\n",
    "parsedData.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#using randomSplit function to split data into trainingRDD and testRDD \n",
    "(trainingData, testData) = parsedData.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3457\n"
     ]
    }
   ],
   "source": [
    "#printing count of trainingRDD\n",
    "print trainingData.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1441\n"
     ]
    }
   ],
   "source": [
    "#printing count of testRDD\n",
    "print testData.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build the model SVM with SGD_l1 classifier\n",
    "model_sgd = SVMWithSGD.train(trainingData,step=0.01,regParam=0.01,iterations=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.064311964067\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on test data\n",
    "labelsAndPreds = testData.map(lambda p: (p.label, model_sgd.predict(p.features)))\n",
    "testErr = labelsAndPreds.filter(lambda (v, p): v != p).count() / float(parsedData.count())\n",
    "print(\"Test Error = \" + str(testErr))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build the model LogisticRegressionWithLBFGS\n",
    "\n",
    "model_lbfgs = LogisticRegressionWithLBFGS.train(trainingData,iterations=1200,regParam=0.1,tolerance=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.0628828093099\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on test data\n",
    "labelsAndPreds = testData.map(lambda p: (p.label, model_lbfgs.predict(p.features)))\n",
    "testErr = labelsAndPreds.filter(lambda (v, p): v != p).count() / float(parsedData.count())\n",
    "print(\"Test Error = \" + str(testErr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build the model LogisticRegressionWithSGD_l2\n",
    "\n",
    "model_sgd_l2 = LogisticRegressionWithSGD.train(trainingData,iterations=1000,regParam=0.1,step=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.064311964067\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on test data\n",
    "labelsAndPreds = testData.map(lambda p: (p.label, model_sgd_l2.predict(p.features)))\n",
    "testErr = labelsAndPreds.filter(lambda (v, p): v != p).count() / float(parsedData.count())\n",
    "print(\"Test Error = \" + str(testErr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build the model LogisticRegressionWithSGD_l1\n",
    "\n",
    "model_sgd_l1 = LogisticRegressionWithSGD.train(trainingData,iterations=500,step=0.1,regParam=0.01,regType='l1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.065741118824\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on test data\n",
    "labelsAndPreds = testData.map(lambda p: (p.label, model_sgd_l1.predict(p.features)))\n",
    "testErr = labelsAndPreds.filter(lambda (v, p): v != p).count() / float(parsedData.count())\n",
    "print(\"Test Error = \" + str(testErr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build the model LogisticRegressionWithSGD_none\n",
    "\n",
    "model_sgd_none = LogisticRegressionWithSGD.train(trainingData,iterations=500,step=0.1,regParam=0.01,regType='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.0667619436505\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on test data\n",
    "labelsAndPreds = testData.map(lambda p: (p.label, model_sgd_none.predict(p.features)))\n",
    "testErr = labelsAndPreds.filter(lambda (v, p): v != p).count() / float(parsedData.count())\n",
    "print(\"Test Error = \" + str(testErr))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
